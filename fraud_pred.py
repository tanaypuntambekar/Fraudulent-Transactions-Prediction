# -*- coding: utf-8 -*-
"""Fraud_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WQQX7YXmqPZ66IismGZ04nzu6anmtWhl

Intern Assignment
"""

from google.colab import drive
drive.mount('/content/drive')

"""Importing Required libraries"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/Fraud.csv')

df.shape

df.head()

"""step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).

type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.

amount - amount of the transaction in local currency.

nameOrig - customer who started the transaction

oldbalanceOrg - initial balance before the transaction

newbalanceOrig - new balance after the transaction

nameDest - customer who is the recipient of the transaction

oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).

newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).

isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.

isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.
"""

df.info()

df.describe()

"""Data Analysis - Missing values, Outliers, multi-collinearity."""

df.isnull().sum()

df.duplicated().sum()

df['type'].value_counts()

df['isFraud'].value_counts()

df['isFlaggedFraud'].value_counts()

sns.countplot(df.type)

plt.figure(figsize=(8,6))
sns.countplot(x='isFraud', data=df)

##coverting categorical features to numerical
from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()
df.type=label.fit_transform(df.type)
df.nameOrig=label.fit_transform(df.nameOrig)
df.nameDest=label.fit_transform(df.nameDest)

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(),annot=True)

corr_matrix = df.corr()
corr_matrix["isFlaggedFraud"].sort_values(ascending=False)

plt.subplot(2, 3, 1)
plt.boxplot(df['amount'])


plt.subplot(2, 3, 2)
plt.boxplot(df['oldbalanceOrg'])


plt.subplot(2, 3, 3)
plt.boxplot(df['newbalanceOrig'])


plt.subplot(2, 3, 4)
plt.boxplot(df['oldbalanceDest'])


plt.subplot(2, 3, 5)
plt.boxplot(df[ 'newbalanceDest'])

plt.show()

##Downsampling to handle imbalance
count_0, count_1 = df['isFraud'].value_counts()
count_0, count_1

df_0 = df[df['isFraud'] == 0]
df_1 = df[df['isFraud'] == 1]

df_0_under = df_0.sample(count_1)

df = pd.concat([df_0_under, df_1],axis=0)

df.shape

df['isFraud'].value_counts()

Q1 = np.percentile(df['amount'],25)
Q3 = np.percentile(df['amount'],75)
IQR = Q3 - Q1

lower_limit = Q1 - 1.5*IQR
upper_limit = Q3 + 1.5*IQR

df = df[(df['amount']>lower_limit) & (df['amount']<upper_limit)]

df.shape

"""Model Building"""

X = df.drop(['isFraud','oldbalanceDest','nameDest','newbalanceDest'],axis =1)
y = df['isFraud']

X

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()

rfc.fit(X_train, y_train)

from sklearn.metrics import classification_report

print(classification_report(y_test, rfc.predict(X_test)))

from sklearn.metrics import average_precision_score

aps2 = average_precision_score(y_test, rfc.predict(X_test))
print(aps2)

from sklearn.model_selection import RandomizedSearchCV

n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(5, 30, num = 5)]
min_samples_split = [2, 5, 10, 15, 100]
min_samples_leaf = [1, 2, 5, 10]

ran_parameters = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
                'bootstrap':[True, False],
                 'criterion':['gini', 'entropy']}

ran_cv = RandomizedSearchCV(estimator=rfc, param_distributions=ran_parameters, cv=3, n_jobs=-1, verbose=2)

ran_cv.fit(X_train, y_train)

print(classification_report(y_test, ran_cv.predict(X_test)))

from xgboost import XGBClassifier

xgb = XGBClassifier()

xgb.fit(X_train, y_train)

print(classification_report(y_test, xgb.predict(X_test)))

"""**conclusion**

Built Random Forest and XGBoost classification models to predict whether transaction is fraud.
Optimized the models with hyperparameter tuning using RandomizedSearchCV.

1 - The dataset doesn't consist any missing value. For ouliers removal I have used the IQR (Interquartile Range) method considering 25 percentile and 75 percentile and considered the data between the upper and the lower limit.

2 - The fraud detection model (XGBoost) tries to analyze the pattern of fraudulent transactions by making use of different modelling techniques and using the results obtained from our study we intend to predict and prevent similar fraud cases in future.The model detects fraud based on factors like type of transaction, amount etc.

3 - For selecting variables including in the model I have plotted the heatmap of correlation. Based on that i removed oldbalanceDest newbalanceDest nameDest columns. Six columns - isFraud, amount, oldbalanceOrg, newbalanceOrig, step and type  are the most important features to be included in the model as they have relatively good correlation with the target column.

4 - The dataset is imbalanced, so here precision matters more than the accuracy. Random Forest model has the highest precision(0.99) and also has the accuracy score of 1.

5 - From the heatmap of correlation, it is seen that step, amount, Type, and isFlaggedFraud are the 4 key factors that predict fraudulent customers.

6 - Yes these factors make sense as we have seen that Cash out and payment are the most comman type which have very high fradaulent transactions.

7 - Setlimit to amount of transaction that can happen, if the tranaction is above the limit the company should add measures to verify the transaction and this transaction should be kept under tight watch.

8 - If these actions are implemented, it woukd bring the situation under control and give the company less overhead to worry after the transaction as there will be tight measures when the transaction is taking place.
"""

